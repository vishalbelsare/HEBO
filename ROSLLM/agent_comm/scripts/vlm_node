#!/usr/bin/env python3
import os
import io
import cv2
import base64
import traceback
from time import time_ns
from datetime import datetime

import rospy
from cv_bridge import CvBridge
from sensor_msgs.msg import Image as ROSImage

from rosllm_msgs.msg import LLMResponse
from rosllm_srvs.srv import VLM as VLMSrv
from rosllm_srvs.srv import VLMResponse as VLMSrvResponse

from agent_comm.vlm import VLM


class VLMNode:
    def __init__(self):
        rospy.init_node("vlm_node")

        # Params mirror your llm_node
        self.model = rospy.get_param("~model")
        self.vlm = VLM(
            model=self.model,
            base_url=rospy.get_param("~base_url"),
            temperature=rospy.get_param("~temperature"),
            timeout=rospy.get_param("~timeout", 30.0),
            api_key=rospy.get_param("~api_key", "EMPTY"),
        )

        # Service only (since the request needs both prompt + image)
        self.srv_req_num = 0
        rospy.Service("call_vlm", VLMSrv, self.handle_service_request)

        self.bridge = CvBridge()

        # Optional: where to stash temp JPEGs
        self.tmp_dir = rospy.get_param("~tmp_dir", "/tmp")
        os.makedirs(self.tmp_dir, exist_ok=True)

        rospy.loginfo("initialized vlm_node, ready to receive VLM requests")

    def _image_to_jpeg_b64(self, img_msg: ROSImage) -> bytes:
        """
        Convert ROS Image to JPEG bytes, then base64-encode and return BYTES.
        """
        # Convert ROS Image -> OpenCV (numpy array). Keep original encoding if possible.
        cv_img = self.bridge.imgmsg_to_cv2(img_msg, desired_encoding="passthrough")

        # If the message is mono or RGBA, you may want to normalize to BGR before encoding.
        # OpenCV imencode handles many types; ensure 8-bit depth.
        if cv_img.dtype != "uint8":
            # Attempt a safe cast if not uint8
            cv_img = cv2.convertScaleAbs(cv_img)

        # Encode as JPEG in-memory
        ok, enc = cv2.imencode(".jpg", cv_img, [int(cv2.IMWRITE_JPEG_QUALITY), 95])
        if not ok:
            raise RuntimeError("Failed to encode image as JPEG")
        jpeg_bytes = enc.tobytes()

        # Persist to disk (as requested) â€“ useful for debugging too
        ts = datetime.utcnow().strftime("%Y%m%dT%H%M%S%fZ")
        fname = os.path.join(self.tmp_dir, f"vlm_{ts}.jpg")
        with open(fname, "wb") as f:
            f.write(jpeg_bytes)
        rospy.logdebug(f"Saved incoming image to {fname}")

        # Return base64 BYTES
        return base64.b64encode(jpeg_bytes)

    def call_vlm(self, prompt: str, img_msg: ROSImage) -> LLMResponse:
        try:
            t0 = time_ns()
            img_b64 = self._image_to_jpeg_b64(img_msg)
            resp_text = self.vlm(prompt, img_b64, mime="image/jpeg")
            t1 = time_ns()
            success = True
            info = f"successfully received response from '{self.model}'"
        except Exception:
            resp_text = ""
            success = False
            info = traceback.format_exc()
            t1 = time_ns()

        resp = LLMResponse(
            success=success,
            response=resp_text,
            info=info,
            req_time=t0,
            res_time=t1,
        )
        resp.header.stamp = rospy.Time.now()
        return resp

    def handle_service_request(self, req):
        rospy.loginfo("vlm_node received request")
        self.srv_req_num += 1

        # req has: req.prompt (string), req.image (sensor_msgs/Image)
        response_msg = self.call_vlm(req.prompt, req.image)
        response_msg.req = self.srv_req_num

        if response_msg.success:
            rospy.loginfo(response_msg.info)
        else:
            rospy.logwarn(response_msg.info)

        return VLMSrvResponse(response=response_msg)

    def spin(self):
        rospy.spin()


def main():
    VLMNode().spin()


if __name__ == "__main__":
    main()
